{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a98a7146",
   "metadata": {},
   "source": [
    "# PyKOALA Data Reduction Sequence (Standard stars)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "845128f2",
   "metadata": {},
   "source": [
    "This notebook contains the basic reduction steps that can be done with pyKOALA for the KOALA instrument."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc2e1691",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from pykoala import __version__\n",
    "import warnings\n",
    "from astropy import units as u\n",
    "# You may want to comment the following line\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "print(\"pyKOALA version: \", __version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b53f3438",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61f2c139",
   "metadata": {},
   "source": [
    "First, let's import a basic module to handle the RSS data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c95d24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykoala.instruments.koala_ifu import koala_rss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ba64c0",
   "metadata": {},
   "source": [
    "The koala_rss is a *DataContainer* that will be used to store the RSS data and track all the changes applied to it.\n",
    "\n",
    "Now let's load some data that we have partially reduced with 2dfdr. The target will be the spectrophotometric standard star HR7596:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "967a34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of RSS objects\n",
    "std_star_rss = []\n",
    "aaomega_arms = {'blue': 1, 'red': 2}\n",
    "# Choose which arm of the spectrograph is going to be used\n",
    "arm = 'red'\n",
    "path_to_data = 'data'\n",
    "\n",
    "for i in [28, 29, 30]:\n",
    "    filename = f\"{path_to_data}/27feb{aaomega_arms[arm]}00{i}red.fits\"\n",
    "    rss = koala_rss(filename)\n",
    "    print(f\"File {filename} corresponds to object {rss.info['name']}\")\n",
    "    std_star_rss.append(rss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad38d869",
   "metadata": {},
   "source": [
    "Now let us start applying some corrections to the data!\n",
    "\n",
    "In this tutorial, we will consider the following corrections:\n",
    "- Instrumental throughput\n",
    "- Atmospheric extinction\n",
    "- Telluric absorption\n",
    "- Sky emission\n",
    "\n",
    "Some of these corrections might not be relevant at a particular wavelength regime. For example, the blue arm of the AAOMega spectrograph 3600-5000 A is not affected by the telluric absorption."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "887ad9af",
   "metadata": {},
   "source": [
    "# Corrections\n",
    "## Instrumental throughput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e36d471",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykoala.corrections.throughput import ThroughputCorrection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29c6b890",
   "metadata": {},
   "source": [
    "The throughput correction accounts for the differences in the efficiency of each fibre in the instrument. This effect also depends on the wavelength that we are using.\n",
    "\n",
    "In pyKOALA (at least version <= 0.1.1) this can be computed from a set of input rss files that correspond to flat exposures as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9e03ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "flat_rss = [koala_rss(\"data/combined_skyflat_red.fits\")]\n",
    "throughput_corr = ThroughputCorrection.from_rss(flat_rss, clear_nan=True,\n",
    "                                                medfilt=10)\n",
    "for i in range(len(std_star_rss)):\n",
    "    std_star_rss[i] = throughput_corr.apply(std_star_rss[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb7fc489",
   "metadata": {},
   "source": [
    "We can assess the quality of our resulting throughput correction by using the built-in quality control plotting functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6357581e",
   "metadata": {},
   "outputs": [],
   "source": [
    "throughput_fig = throughput_corr.throughput.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6516ae7d",
   "metadata": {},
   "source": [
    "Each correction is recorded within the `history` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b621677d",
   "metadata": {},
   "outputs": [],
   "source": [
    "std_star_rss[0].history.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35b67be2",
   "metadata": {},
   "source": [
    "## Atmospheric extinction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9918674",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykoala.corrections.atmospheric_corrections import AtmosphericExtCorrection\n",
    "\n",
    "AtmosphericExtCorrection?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c23d0fa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "atm_ext_corr = AtmosphericExtCorrection.from_text_file(AtmosphericExtCorrection.default_extinction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc82cf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(std_star_rss)):\n",
    "    std_star_rss[i] = atm_ext_corr.apply(std_star_rss[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c72930",
   "metadata": {},
   "source": [
    "## Telluric absorption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af4fb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykoala.corrections.sky import TelluricCorrection, combine_telluric_corrections\n",
    "from pykoala.corrections.wavelength import TelluricWavelengthCorrection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d2bff0",
   "metadata": {},
   "source": [
    "There are two ways of estimating the Tellucir correction: using a default model or using an empirical approach from the data.\n",
    "\n",
    "In this example, we will compute a telluric correction for each input RSS, and later we will combine all of them into a final one. Alternatively, the user might want to first combine all the RSS data, and then compute the effective telluric absorption correction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fee39416",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_telluric_corrections = []\n",
    "for i in range(len(std_star_rss)):\n",
    "    telluric_correction, fig = TelluricCorrection.from_model(\n",
    "        std_star_rss[i], plot=True, width=30)\n",
    "    # Reopen the figure\n",
    "    plt.figure(fig)\n",
    "    telluric_correction.flag_data_container(\n",
    "        std_star_rss[i], telluric_correction=telluric_correction.telluric_correction,\n",
    "        wavelength=telluric_correction.wavelength)\n",
    "    wavelength_correction, wave_offset_figs = TelluricWavelengthCorrection.from_rss(\n",
    "    std_star_rss[i], median_smooth=5, oversampling=1, pol_fit_deg=2, \n",
    "    plot=True)\n",
    "\n",
    "    # Recompute the telluric correction\n",
    "    telluric_correction, fig = TelluricCorrection.from_model(\n",
    "        std_star_rss[i], plot=True, width=30)\n",
    "    # Apply the correction to the star\n",
    "    std_star_rss[i] = telluric_correction.apply(std_star_rss[i])\n",
    "    all_telluric_corrections.append(telluric_correction)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa481939",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykoala.corrections.wavelength import TelluricWavelengthCorrection\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a14716f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Create the final telluric correction and save the result\n",
    "\n",
    "final_telluric_correction = combine_telluric_corrections(\n",
    "    all_telluric_corrections, ref_wavelength=std_star_rss[0].wavelength)\n",
    "final_telluric_correction.save(filename=f\"products/telluric_correction_{arm}.dat\")\n",
    "\n",
    "plt.figure()\n",
    "plt.subplot(111)\n",
    "plt.plot(final_telluric_correction.wavelength, final_telluric_correction.telluric_correction, c='c')\n",
    "plt.ylabel('Telluric correction')\n",
    "plt.xlabel('Wavelength')\n",
    "plt.ylim(0.95, 2.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47693752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3be3280e",
   "metadata": {},
   "source": [
    "## Sky emission\n",
    "\n",
    "This is quite a difficult correction. In particular, KOALA does not count with auxiliary sky fibres that allow to estimate the sky brightness simultaneous to the acquisition of data. Therefore, the estimation of the sky contribution must be inferred from the science exposure or from offset sky frames taken between the observing sequence. \n",
    "\n",
    "At present, pyKOALA provides several ways to estimate a sky emission model... See the sky emission tutorial for a more detailed discussion."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a45994c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykoala.corrections import sky\n",
    "sky.SkyFromObject?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c057162b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(std_star_rss)):\n",
    "    skymodel = sky.SkyFromObject(std_star_rss[i], bckgr_estimator='mad', source_mask_nsigma=3, remove_cont=False)\n",
    "    skycorrection = sky.SkySubsCorrection(skymodel)\n",
    "    \n",
    "    # Store the value of the RSS intensity before substraction\n",
    "    intensity_no_sky = std_star_rss[i].intensity.copy()\n",
    "\n",
    "    std_star_rss[i], _ = skycorrection.apply(std_star_rss[i])\n",
    "    \n",
    "    # Compare between the two versions of the data\n",
    "    fig = plt.figure(figsize=(10, 4))\n",
    "    ax = fig.add_subplot(121)\n",
    "    mappable = ax.imshow(np.log10(std_star_rss[i].intensity.value),\n",
    "                         origin='lower', aspect='auto',\n",
    "                         interpolation='none', cmap='jet')\n",
    "    plt.colorbar(mappable, ax=ax, label=f'{std_star_rss[i].intensity.unit}')\n",
    "    ax = fig.add_subplot(122)\n",
    "    mappable = ax.imshow(np.log10(intensity_no_sky / std_star_rss[i].intensity),\n",
    "                         vmin=-0.7, vmax=.7, origin='lower', aspect='auto',\n",
    "                         interpolation='none', cmap='jet')\n",
    "    plt.colorbar(mappable, ax=ax, label=r'$\\log_{10}(\\frac{I_{nosky}}{I_{skycorr}})$')\n",
    "    plt.subplots_adjust(wspace=0.3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d869af2a",
   "metadata": {},
   "source": [
    "# Cubing\n",
    "\n",
    "For the final part of this tutorial, now we will see how to combine a set of RSS data into a 3D datacube.\n",
    "\n",
    "- (optional) The first step would consists of registering the data, i.e., account for the spatial offset between the different frames eigther produced by instrumental innacuracies or due to the application of dithering patterns.\n",
    "- ADR correction. The data might be affected by atmospheric differential refraction, producing a wavelength-dependent shift of the image.\n",
    "- Cube interpolation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cff99b",
   "metadata": {},
   "source": [
    "## Registration\n",
    "\n",
    "The registration of RSS frames is part of the Astrometry correction module. To register a set of stardad star frames, we will use the function `AstrometryCorrection.register_centroids` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e33d4607",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykoala.corrections.astrometry import AstrometryCorrection\n",
    "\n",
    "astrom_corr = AstrometryCorrection()\n",
    "\n",
    "star_name = std_star_rss[0].info['name'].split()[0]\n",
    "offsets, fig = astrom_corr.register_centroids(std_star_rss, object_name=star_name,\n",
    "                                         qc_plot=True, centroider='gauss')\n",
    "for offset in offsets:\n",
    "    print(\"Offset (ra, dec) in arcsec: \", offset[0].to('arcsec'), offset[1].to('arcsec'))\n",
    "\n",
    "for rss, offset in zip(std_star_rss, offsets):\n",
    "    astrom_corr.apply(rss, offset=offset)\n",
    "\n",
    "# Check that the corrections has been logged\n",
    "rss.history.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0cd31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cddf1d9",
   "metadata": {},
   "source": [
    "## Atmospheric differential refraction\n",
    "\n",
    "Accounting for this correction is way more easier with standard stars than with extended sources. The idea is to track the centroid of the star as function of wavelength to derive the offsets produced by the ADR."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f908c191",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykoala.corrections.atmospheric_corrections import get_adr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b9ee12",
   "metadata": {},
   "outputs": [],
   "source": [
    "adr_corr_set = []\n",
    "\n",
    "for rss in std_star_rss:\n",
    "    adr_pol_ra, adr_pol_dec, fig = get_adr(rss, max_adr=0.5, pol_deg=2,\n",
    "                                        plot=True)\n",
    "    adr_corr_set.append([adr_pol_ra, adr_pol_dec])\n",
    "    plt.show(plt.figure(fig))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "807221a5",
   "metadata": {},
   "source": [
    "## RSS cubing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0631f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykoala.cubing import build_cube, build_wcs\n",
    "from pykoala.plotting.utils import qc_cube"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b700778a",
   "metadata": {},
   "source": [
    "For interpolating RSS data into a 3D datacube we will make use of the function *build_cube*. This method requires as input:\n",
    "- A list of RSS objects. \n",
    "- An `astropy.wcs.WCS` instance describing the dimensions of the cube, or a dictionary containing the basic information for initialising a `WCS`.\n",
    "- The characteristic size of the kernel interpolation function expressed in arcseconds.\n",
    "- A list containing the ADR correction for every RSS (it can contain None) in the form: [(ADR_ra_1, ADR_dec_1), (ADR_ra_2, ADR_dec_2), (None, None)]. Note that for the first two RSS we would be providing some corrections, while the latter would not be corrected.\n",
    "\n",
    "To facilitate the creation of `WCS` objects, we provide a function `build_wcs`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecae822f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of pixels along the three dimensions\n",
    "datacube_shape = (std_star_rss[0].wavelength.size, 40, 60)\n",
    "# Reference position along the three axes.\n",
    "ref_position = (std_star_rss[0].wavelength[0],\n",
    "                np.mean(std_star_rss[0].info['fib_ra']),\n",
    "                np.mean(std_star_rss[0].info['fib_dec']))\n",
    "# Spatial pixel scale size in deg\n",
    "spatial_pixel_size = 1.0 << u.arcsec\n",
    "# Spectral pixel scale in angstrom\n",
    "spectral_pixel_size = std_star_rss[0].wavelength[1] - std_star_rss[0].wavelength[0]\n",
    "\n",
    "wcs = build_wcs(datacube_shape=datacube_shape,\n",
    "                reference_position=ref_position,\n",
    "                spatial_pix_size=spatial_pixel_size,\n",
    "                spectra_pix_size=spectral_pixel_size,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc8d5bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cube = build_cube(rss_set=std_star_rss,\n",
    "                  wcs=wcs,\n",
    "                  kernel_size_arcsec=1.0,\n",
    "                  # Additional information that will be stored in the *info* dictionary\n",
    "                  cube_info=dict(name=star_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6e68c76",
   "metadata": {},
   "source": [
    "To assess the performance of the cubing, we can run the QC method *qc_cube*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280404f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "qc_cube(cube)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbdae735",
   "metadata": {},
   "source": [
    "# Flux calibration\n",
    "\n",
    "The final step will consists of deriving the instrumental response function that converts the signal in counts into physical units accounting for the instrumental chromatic flux loss.\n",
    "\n",
    "To build a `FluxCalibration` correction we can provide a path to a text file that already contains the response function:\n",
    "```\n",
    "flux_correction = FluxCalibration.from_text_file(\"path/to/file\")\n",
    "```\n",
    "This file must contain two columns that correspond to the wavelength and response function, respectively.\n",
    "\n",
    "Alternatively, we can estimate the response function by means of observations of standard stars.\n",
    "\n",
    "- First, we can extract the spectra from the data by modelling the instrumental PSF using a Moffat or Gaussian model:\n",
    "```\n",
    "FluxCalibration.extract_stellar_flux(data_container)\n",
    "```\n",
    "- Then, we can estimate the response using:\n",
    "```\n",
    "FluxCalibration.get_response_curve(obs_wavelength, obs_spectra, reference_wavelength, reference_spectra)\n",
    "```\n",
    "See the methods documentation for details.\n",
    "\n",
    "Finally, `FluxCalibration` includes a semi-automatic method (`FluxCalibration.auto`) for building the correction from a set of standard stars. In this example we will use a single star, but the final response function can combine the results from several objects. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665f852",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pykoala.corrections.flux_calibration import FluxCalibration\n",
    "\n",
    "# Basic configuration for the extraction of the stellar spectra from the cube\n",
    "# wave_range = None ---> use the whole range of wavelength\n",
    "# wave_window = 50 ---> Number of resolution elements or \"spectral pixels\" to average\n",
    "extract_args = dict(wave_range=None, wave_window=5, plot=True)\n",
    "# Basic configuration for the estimation of the response function\n",
    "# median_filter_n ---> Apply a median filter on the observed data prior fit.\n",
    "# spline = True ---> Fit a spline\n",
    "response_params = dict(pol_deg=None, spline=True, median_filter_n=20, spline_args={'s':10},\n",
    "                           plot=True)\n",
    "\n",
    "flux_cal_results, flux_corrections, master_flux_corr = FluxCalibration.auto(\n",
    "    data=[cube],\n",
    "    calib_stars=[cube.info['name']],\n",
    "    fnames=None,\n",
    "    extract_args=extract_args,\n",
    "    response_params=response_params,\n",
    "    combine=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7b900f9",
   "metadata": {},
   "source": [
    "In this example we have extrated the flux of a single star (HILT600) to build a `FluxCalibrationCorrection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84d7b77a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flux_cal_results['HILT600'].keys())\n",
    "flux_cal_results['HILT600']['extraction']['figure']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4a3f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(flux_cal_results['HILT600'].keys())\n",
    "# Show the figure\n",
    "flux_cal_results['HILT600']['response_fig']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a4d371",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the reponse function\n",
    "master_flux_corr.save_response('products/response_HILT600_transfer_function.dat')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
